run-command:
  stage: CommandCopy_SSM
  script:
    - |
      set -euo pipefail

      # 1) Write the remote payload locally with a LITERAL heredoc (no interpolation)
      cat > remote_payload.sh <<'BASH'
      #!/usr/bin/env bash
      set -euo pipefail

      LOG_DIR="/var/log/fednow-infra-fraud-sp"
      CONFIG_DIR="/persistent/instance/cfg"
      MODEL_DIR="/persistent/data/journal/import"
      CONFIG_FILES=(settings.iris cluster.iris)

      TMP_DIR="/data/tmp/staging"
      mkdir -p "$TMP_DIR"

      : "${TS:?TS is required}"
      DATE_PREFIX="${TS}_unredacted"

      LOG_TAR="${TMP_DIR}/logs_${DATE_PREFIX}.tar.gz"
      CONFIG_TAR="${TMP_DIR}/config_${DATE_PREFIX}.tar.gz"
      MODEL_TAR="${TMP_DIR}/model_${DATE_PREFIX}.tar.gz"

      S3_BUCKET="s3://n-fn-dev-752a9224-consul-backups-usge1"
      S3_PREFIX="sp/support/unredacted/${DATE_PREFIX}"

      echo "Creating tarballs..."
      tar -czf "$LOG_TAR"   -C "$(dirname "$LOG_DIR")"   "$(basename "$LOG_DIR")"
      tar -czf "$MODEL_TAR" -C "$(dirname "$MODEL_DIR")" "$(basename "$MODEL_DIR")"
      tar -czf "$CONFIG_TAR" -C "$CONFIG_DIR" "${CONFIG_FILES[@]}"

      echo "Uploading to S3..."
      aws s3 cp "$LOG_TAR"   "${S3_BUCKET%/}/${S3_PREFIX}/"
      aws s3 cp "$CONFIG_TAR" "${S3_BUCKET%/}/${S3_PREFIX}/"
      aws s3 cp "$MODEL_TAR"  "${S3_BUCKET%/}/${S3_PREFIX}/"
      BASH
      chmod +x remote_payload.sh

      # 2) Base64 the script (BSD & GNU compatible)
      REMOTE_B64=$(base64 -w0 remote_payload.sh 2>/dev/null || base64 < remote_payload.sh)

      # 3) Send command: decode + run with bash (no tricky quoting)
      CMD_ID=$(
        aws ssm send-command \
          --document-name "AWS-RunShellScript" \
          --instance-ids "$INSTANCE_ID" \
          --region "$AWS_REGION" \
          --comment "Tar & upload (${CI_PIPELINE_ID})" \
          --parameters '{
            "executionTimeout": ["3600"],
            "commands": [
              "set -euo pipefail",
              "echo '"$REMOTE_B64"' | base64 -d > /tmp/remote_payload.sh",
              "chmod +x /tmp/remote_payload.sh",
              "export TS='"$TS"'",                 # pass TS down
              "bash /tmp/remote_payload.sh"
            ]
          }' \
          --query "Command.CommandId" --output text
      )
      echo "SSM CommandId: $CMD_ID"

      # 4) Poll for completion
      for _ in $(seq 1 60); do
        STATUS=$(aws ssm get-command-invocation \
          --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" \
          --region "$AWS_REGION" --query 'Status' --output text || true)
        echo "Status: $STATUS"
        case "$STATUS" in
          Success) break ;;
          Failed|Cancelled|TimedOut)
            aws ssm get-command-invocation \
              --command-id "$CMD_ID" --instance-id "$INSTANCE_ID" \
              --region "$AWS_REGION" --query 'StandardErrorContent' --output text || true
            exit 1 ;;
        esac
        sleep 5
      done
      [ "$STATUS" = "Success" ] || { echo "RunCommand did not complete in time"; exit 1; }

      # 5) Download, extract, redact, zip
      ARCHIVE_NAME="${TS}_unredacted"
      S3_PREFIX="sp/support/unredacted/${ARCHIVE_NAME}"

      mkdir -p "./${ARCHIVE_NAME}"
      aws s3 cp "s3://${S3_BUCKET}/${S3_PREFIX}/" "./${ARCHIVE_NAME}/" --recursive --region "$AWS_REGION"

      mkdir -p "${ARCHIVE_NAME}/extracted"
      shopt -s nullglob
      for f in "${ARCHIVE_NAME}"/*.tar.gz; do
        name="$(basename "$f" .tar.gz)"
        mkdir -p "${ARCHIVE_NAME}/extracted/${name}"
        tar -xzf "$f" -C "${ARCHIVE_NAME}/extracted/${name}"
      done
      shopt -u nullglob

      python redact.py "${ARCHIVE_NAME}/extracted/"
      zip -rq "redacted_logs_${CI_PIPELINE_ID}.zip" "${ARCHIVE_NAME}/extracted/"
  artifacts:
    name: redacted-logs-$CI_PIPELINE_ID
    when: always
    expire_in: 14 days
    paths:
      - redacted_logs_${CI_PIPELINE_ID}.zip
